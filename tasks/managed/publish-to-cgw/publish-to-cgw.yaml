---
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: publish-to-cgw
  labels:
    app.kubernetes.io/version: "0.3.0"
  annotations:
    tekton.dev/pipelines.minVersion: "0.12.1"
    tekton.dev/tags: release
spec:
  description: >-
    Tekton task to publish content to CGW (Content-Gateway)
  params:
    - name: cgwHostname
      type: string
      description: >
        The hostname of the content-gateway to publish the metadata to
      default: https://developers.redhat.com/content-gateway/rest/admin
    - name: cgwSecret
      type: string
      description: >
        The kubernetes secret to use to authenticate to content-gateway.
        It needs to contain two keys: username and token
      default: publish-to-cgw-secret
    - name: dataPath
      type: string
      description: >
        Path to the JSON string of the merged data to use in the data workspace.
    - name: contentDir
      type: string
      description: Path where the content to push is stored in the workspace
  results:
    - name: resultDataPath
      type: string
      description: |
        The relative path in the workspace to the stored json of result data of the task
  workspaces:
    - name: data
      description: Workspace to save the CR jsons to
  steps:
    - name: run-push-cgw-metadata
      image: quay.io/konflux-ci/release-service-utils:3826e42200d46e2bd336bc7802332190a9ebd860
      env:
        - name: CGW_USERNAME
          valueFrom:
            secretKeyRef:
              name: $(params.cgwSecret)
              key: username
        - name: CGW_PASSWORD
          valueFrom:
            secretKeyRef:
              name: $(params.cgwSecret)
              key: token
      script: |
        #!/usr/bin/env bash
        python3 <<EOF
        """
        This script interacts with the Content Gateway (CGW) API to create and manage 
        files for a specified product and version. It performs the following tasks:
        1. Get Product ID and Version ID from CGW API.
        2. Extract all components under contentGateway key from dataPath
        3. Find all the files in contentDir that starts with the component name
        4. Generate necessary metadata for each file
        5. Create files using the metadata and skip if the file already exists
        6. Rollback created files on failure
        7. Dump the metadata to a YAML file
        8. Dump the result data to a JSON file
        """

        import os
        import json
        import hashlib
        import requests
        from requests.auth import HTTPBasicAuth
        import yaml

        # Environment variables
        BASE_URL = "$(params.cgwHostname)"
        USERNAME = os.getenv("CGW_USERNAME")
        PASSWORD = os.getenv("CGW_PASSWORD")

        DATA_FILE = "$(workspaces.data.path)/$(params.dataPath)"
        CONTENT_DIR = "$(workspaces.data.path)/$(params.contentDir)"

        # Grab the path of datafile and use that as workspace directory
        WORKSPACE_DIR = os.path.dirname(DATA_FILE)
        METADATA_FILE_PATH = f"{WORKSPACE_DIR}/cgw_metadata.yaml"
        RESULT_FILE_JSON_PATH = f"{WORKSPACE_DIR}/results.json"

        # Default values for each component,
        # values from DATA_FILE takes presedence over these
        default_values_per_component = {
            "type": "FILE",
            "hidden": False,
            "invisible": False,
            "order": 0,
        }

        def generate_download_url(file_name):
            """
            Generate a download URL in this format:
            /content/origin/files/sha256/{checksum[:2]}{checksum}/{file_name}
            """
            prefix = "/content/origin/files/sha256"
            sha256_hash = hashlib.sha256()
            with open(CONTENT_DIR + "/" + file_name, "rb") as f:
                for byte_block in iter(lambda: f.read(4096), b""):
                    sha256_hash.update(byte_block)
            checksum = sha256_hash.hexdigest()
            return f"{prefix}/{checksum[:2]}/{checksum}/{file_name}"

        def call_cgw_api(method, endpoint, data=None):
            """Make an API call to the Content Gateway service."""
            try:
                response = requests.request(
                    method=method.upper(),
                    url=f"{BASE_URL}{endpoint}",
                    headers={"Accept": "application/json", "Content-Type": "application/json"},
                    auth=HTTPBasicAuth(USERNAME, PASSWORD),
                    json=data,
                )
                response.raise_for_status()
                return response
            except requests.RequestException as e:
                raise requests.RequestException({e.response.text})

        def get_product_id(product_name):
            """Retrieve the product ID by name."""
            products = call_cgw_api("GET", "/products")
            products = products.json()
            for product in products:
                if product.get("name") == product_name:
                    return product.get("id")
            raise ValueError(f"Product not found: {product_name}")

        def get_version_id(product_id, version_name):
            """Retrieve the version ID for a specific product."""
            versions = call_cgw_api("GET", f"/products/{product_id}/versions")
            versions = versions.json()
            for version in versions:
                if version.get("versionName") == version_name:
                    return version.get("id")
            raise ValueError(f"Version not found: {version_name}")

        def generate_metadata(content_list, components, product_id, productVersion_id):
            """
            Generate metadata for each file in
            content_list that starts with the component name
            """
            shortURL_base = "/pub/"
            if mirrorOpenshiftPush:
                shortURL_base = "/pub/cgw"
            metadata = []
            shasum_files_processed = []
            for file in content_list:
                matching_component = None
                for component in components:
                    if file.startswith(component["name"]):
                        matching_component = component.copy()
                        break

                if matching_component:
                    print("Processing file: ", file)
                    matching_component.update(
                        {
                            "productVersionId": productVersion_id,
                            "downloadURL": generate_download_url(file),
                            "shortURL": f"{shortURL_base}/{product_id}/{productVersion_id}/{file}",
                            "label": file,
                        }
                    )
                    del matching_component["name"]
                    metadata.append(
                        {"type": "file", **default_values_per_component, **matching_component}
                    )
                else:
                    if file.startswith("sha256") and file not in shasum_files_processed:
                        shasum_files_processed.append(file)
                        print("Processing file: ", file)
                        if file.endswith(".gpg"):
                            label = "Checksum - GPG"
                        elif file.endswith(".sig"):
                            label = "Checksum - Signature"
                        elif file.endswith(".txt"):
                            label = "Checksum"

                        metadata.append(
                            {
                                "productVersionId": productVersionId,
                                "downloadURL": generate_download_url(file),
                                "shortURL": f"{shortURL_base}/{product_id}/{productVersion_id}/{file}",
                                "label": label,
                                **default_values_per_component,
                            }
                        )
                    else:
                        # Skip files that do not start with any component name or
                        # sha256
                        print(
                            f"Skipping file: {file} as it does not start with any \
                            component name"
                        )
                        continue

            return metadata

        def file_already_exists(existing_files, new_file):
            """Check if a file already exists."""
            return any(
                all(
                    file.get(key) == new_file.get(key)
                    for key in ["description", "label", "downloadURL", "shortURL"]
                )
                for file in existing_files
            )

        def create_files(product_id, version_id, metadata):
            """Create files using the metadata and rollback on failure."""
            created_files = []
            skipped_files = []
            try:
                existing_files = call_cgw_api(
                    "GET", f"/products/{product_id}/versions/{version_id}/files"
                )
                existing_files = existing_files.json()
                for file_metadata in metadata:
                    if file_already_exists(existing_files, file_metadata):
                        skipped_files.append(file_metadata.get("id"))
                        print(
                            f"Skipping creation: File {file_metadata['label']} already exists with ShortURL {file_metadata['shortURL']}"
                        )
                        continue
                    print(
                        f"Creating file: {file_metadata['label']} with ShortURL {file_metadata['shortURL']}"
                    )
                    created_file = call_cgw_api(
                        "POST",
                        f"/products/{product_id}/versions/{version_id}/files",
                        file_metadata,
                    )
                    print(
                        f"Created file: {file_metadata['label']} with ShortURL {file_metadata['shortURL']}"
                    )
                    created_files.append(created_file.json())
                return created_files, skipped_files
            except Exception as e:
                rollback_files(product_id, version_id, created_files)
                raise Exception(f"Failed to create file: {e}")

        def rollback_files(product_id, version_id, created_files):
            """Rollback created files by ID."""
            for file in created_files:
                try:
                    call_cgw_api(
                        "DELETE", f"/products/{product_id}/versions/{version_id}/files/{file}"
                    )
                except Exception as e:
                    raise Exception(f"Failed to rollback file: {e}")

        try:
            with open(DATA_FILE, "r") as file:
                data = json.load(file)
            os.makedirs(WORKSPACE_DIR, exist_ok=True)
            
            productName = data["contentGateway"]["productName"]
            productCode = data["contentGateway"]["productCode"]
            productVersionName = data["contentGateway"]["productVersionName"]
            mirrorOpenshiftPush = data["contentGateway"].get("mirrorOpenshiftPush")
            components = data["contentGateway"]["components"]
            content_list = os.listdir(CONTENT_DIR)

            productId = get_product_id(productName)
            productVersionId = get_version_id(productId, productVersionName)
            metadata = generate_metadata(content_list, components, productId, productVersionId)
            created, skipped = create_files(productId, productVersionId, metadata)

            with open(METADATA_FILE_PATH, "w") as file:
                yaml.dump(metadata, file, default_flow_style=False, sort_keys=False)
            print(f"YAML content dumped to {METADATA_FILE_PATH}")

            result_data = {
                "no_of_files_processed": len(metadata),
                "no_of_files_created": len(created),
                "no_of_files_skipped": len(skipped),
                "metadata_file_path": METADATA_FILE_PATH,
            }

            print(f"{len(created)} files created and {len(skipped)} files skipped")

            with open(RESULT_FILE_JSON_PATH, "w") as f:
                json.dump(result_data, f)
            with open("$(results.resultDataPath.path)", "w") as f:
                f.write(RESULT_FILE_JSON_PATH)

        except Exception as e:
            print(f"Error: {e}")
            exit(1)
        EOF
